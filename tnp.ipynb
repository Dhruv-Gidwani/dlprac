{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "t1JUugfP1uXp"
   },
   "outputs": [],
   "source": [
    "#Demonstrate use of tensorflow and pytorch by implementing simple code in python\n",
    "# Tensor Flow:\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "x=np.random.rand(100).astype(np.float32)    # Generate 100 random floats between 0 and 1 for x\n",
    "\n",
    "y=0.2*x+0.2    # Generate y values with a simple linear relationship to x\n",
    "\n",
    "W=tf.Variable(np.random.normal([1]))    # Initialize W randomly\n",
    "b=tf.Variable(np.zeros([1]))    # Initialize b to 0\n",
    "\n",
    "#Loss Function (Mean Squared Error)\n",
    "def mse_loss():\n",
    "    y_pred = W*x +b    # Predicted y based on current W and b\n",
    "    loss=tf.reduce_mean(tf.square(y_pred-y))     # Calculate mean squared error\n",
    "    return loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "3yGMnpAb1weg"
   },
   "outputs": [],
   "source": [
    "optimizer= tf.keras.optimizers.Adam()    \n",
    "# We use the Adam optimizer to adjust W and b to minimize the loss.\n",
    "# Adam is a popular optimization algorithm that uses adaptive learning rates, often improving the efficiency of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DcQrU4Uv2g2Z",
    "outputId": "a73935a4-0f7b-4e23-bd9d-d7213524ca2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: W=[0.64984648], b=[-0.00099994], Loss=0.01759412460612659\n",
      "Step 500: W=[0.30262059], b=[0.14751121], Loss=0.000880661601628786\n",
      "Step 1000: W=[0.20776764], b=[0.1960279], Loss=5.07074960481631e-06\n",
      "Step 1500: W=[0.20014956], b=[0.19992352], Loss=1.8911910107881953e-09\n",
      "Step 2000: W=[0.20000053], b=[0.19999974], Loss=2.3335377046340104e-14\n",
      "Step 2500: W=[0.2], b=[0.2], Loss=9.672608815603763e-17\n",
      "Step 3000: W=[0.2], b=[0.2], Loss=9.672314999778486e-17\n",
      "Step 3500: W=[0.2], b=[0.2], Loss=9.67231499800349e-17\n",
      "Step 4000: W=[0.2], b=[0.2], Loss=9.672314999635881e-17\n",
      "Step 4500: W=[0.2], b=[0.2], Loss=9.672315001786919e-17\n"
     ]
    }
   ],
   "source": [
    "for step in range(5000):\n",
    "    with tf.GradientTape() as tape:    # tracks the operations on W and b, allowing TensorFlow to compute gradients (how much each parameter should be adjusted).\n",
    "        current_loss = mse_loss()    # gets the current error of the model.\n",
    "\n",
    "    # Compute gradients\n",
    "    gradients = tape.gradient(current_loss, [W, b])    # calculates the gradients for W and b, which indicate the direction and magnitude of adjustments needed.\n",
    "\n",
    "    # Update weights\n",
    "    optimizer.apply_gradients(zip(gradients, [W, b]))    # applies the calculated adjustments to W and b.\n",
    "\n",
    "    if step % 500 == 0:    # Every 500 steps, it prints the values of W, b, and the loss so we can see the training progress.\n",
    "        # Print current values of W, b, and loss\n",
    "        print(f\"Step {step}: W={W.numpy()}, b={b.numpy()}, Loss={current_loss.numpy()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "v486p5cV2pJt"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Pytorch\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      3\u001b[0m data1\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m      4\u001b[0m     [\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m],\n\u001b[0;32m      5\u001b[0m     [\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m]\n\u001b[0;32m      6\u001b[0m ]\n\u001b[0;32m      8\u001b[0m data2\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m      9\u001b[0m     [\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m2\u001b[39m],\n\u001b[0;32m     10\u001b[0m     [\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m     11\u001b[0m ]\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "#Pytorch\n",
    "import torch\n",
    "data1=[\n",
    "    [1,2],\n",
    "    [3,4]\n",
    "]\n",
    "\n",
    "data2=[\n",
    "    [2,2],\n",
    "    [2,2]\n",
    "]\n",
    "\n",
    "x_data1= torch.tensor(data1)\n",
    "x_data2= torch.tensor(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "t_Y9PAzg8FJp"
   },
   "outputs": [],
   "source": [
    "addition=x_data1+x_data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GaJYtAOF8eKq",
    "outputId": "8e80d442-f4ab-498a-f800-b63fdec72b04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Addition of tensors: tensor([[3, 4],\n",
      "        [5, 6]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Addition of tensors:\", addition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "3o3-ZxH68klv"
   },
   "outputs": [],
   "source": [
    "multiply=x_data1*x_data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-js8PFTg8oGp",
    "outputId": "c3bd8ae2-fc6f-40a4-f3b8-7e22962dca46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiplication of Tensors:  tensor([[2, 4],\n",
      "        [6, 8]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Multiplication of Tensors: \", multiply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C9uDvl2B8tJj"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
